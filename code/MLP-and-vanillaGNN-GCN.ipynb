{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7efc70e-36b6-4f2d-b984-fb41bf3d7b29",
   "metadata": {},
   "source": [
    "## Import Cora and Facebook/Page-Page daasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4012426d-bef6-4bc1-8195-6b025c482bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Data(x=[22470, 128], edge_index=[2, 342004], y=[22470], train_mask=[18000], val_mask=[1999], test_mask=[2469])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import FacebookPagePage\n",
    "\n",
    "dataset_cora = Planetoid(root=\"../data\", name=\"Cora\")\n",
    "dataset_facebook = FacebookPagePage(root=\"../data/Facebook-Page-Page\")\n",
    "\n",
    "data_cora = dataset_cora[0]\n",
    "data_facebook = dataset_facebook[0]\n",
    "\n",
    "# Unlike Cora, Facebook Page-Page doesnâ€™t have training, evaluation, and test masks by\n",
    "# default. We can arbitrarily create masks with the range() function:\n",
    "data_facebook.train_mask = range(18000)\n",
    "data_facebook.val_mask = range(18001, 20000)\n",
    "data_facebook.test_mask = range(20001, 22470)\n",
    "\n",
    "print(data_cora)\n",
    "print(data_facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ba3dc-ddb0-4629-a81c-86e5736fea50",
   "metadata": {},
   "source": [
    "Cora is a popular dataset for node classification in the scientific literature. It represents a network of 2,708 publications (**nodes**), where each connection is a reference (**edge**). Each publication is described as a binary vector of 1,433 unique words (**node features**), where 0 and 1 indicate the absence or presence of the corresponding word, respectively. Each node has a class label from 7 **classes**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917c116-99d7-4d4d-98bd-fcd6a42ce6e0",
   "metadata": {},
   "source": [
    "## Classifying nodes with vanilla neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9165e5-ab80-4de6-aa67-4e2e19da6c10",
   "metadata": {},
   "source": [
    "We will consider node features (i.e., 1,433) as a regular tabular dataset. We will train a simple neural\n",
    "network (MLP) on this dataset to classify our nodes. Note that this architecture does not take into account\n",
    "the topology of the network. We will try to fix this issue with a vanilla GNN and GCN, then compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc6b31e-c00a-445c-b630-2e4f5110df9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows Ã— 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "2703  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
       "2704  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2705  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2706  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      1427  1428  1429  1430  1431  1432  label  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "...    ...   ...   ...   ...   ...   ...    ...  \n",
       "2703   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2704   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2705   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2706   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2707   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[2708 rows x 1434 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is just to show the feature matrix and class vector (we need torch.Tensor type input --> data_cora.x)\n",
    "df_x = pd.DataFrame(data_cora.x.numpy()) # 1,433 columns\n",
    "df_x['label'] = pd.DataFrame(data_cora.y) # adding a label-column\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec16c842-d6e6-49aa-81d5-7407645d7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e932d29-f64f-4ed5-8f02-7d55c9fad590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(dim_input, dim_hidden)\n",
    "        self.linear2 = Linear(dim_hidden, dim_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model_cora = MLP(dataset_cora.num_features, 16, dataset_cora.num_classes)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "model_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6778d965-a6b3-40c3-9d78-9ffdf19f0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1433])\n",
      "tensor([[-1.9757, -1.9887, -2.0736, -1.8290, -1.9392, -1.9986, -1.8399]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([1, 7])\n",
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "input = data_cora.x[:1,:]\n",
    "print(input.shape)\n",
    "print(model_cora(input))\n",
    "print(model_cora(input).shape)\n",
    "print(model_cora(input).argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f64cb8-d859-4fe8-8b28-e78896700bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple accuracy metric (not the best metric for multiclass classification) \n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss() # loss\n",
    "optimizer = torch.optim.Adam(model_cora.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06675633-5d2b-4d15-9641-fecc6d0e122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.948 | Train Acc: 13.57%| Val Loss: 1.93 | Val Acc: 28.00%\n",
      "Epoch  20 | Train Loss: 0.490 | Train Acc: 99.29%| Val Loss: 1.59 | Val Acc: 46.80%\n",
      "Epoch  40 | Train Loss: 0.080 | Train Acc: 100.00%| Val Loss: 1.40 | Val Acc: 53.40%\n",
      "Epoch  60 | Train Loss: 0.032 | Train Acc: 100.00%| Val Loss: 1.42 | Val Acc: 52.80%\n",
      "Epoch  80 | Train Loss: 0.020 | Train Acc: 100.00%| Val Loss: 1.42 | Val Acc: 52.60%\n",
      "Epoch 100 | Train Loss: 0.015 | Train Acc: 100.00%| Val Loss: 1.40 | Val Acc: 52.20%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model on Cora dataset\n",
    "model_cora.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_cora(data_cora.x)\n",
    "    loss = criterion(y_pred[data_cora.train_mask], data_cora.y[data_cora.train_mask]) # loss = criterion(y_pred, y_true)\n",
    "    acc = accuracy(y_pred[data_cora.train_mask].argmax(dim=1), data_cora.y[data_cora.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_cora.val_mask], data_cora.y[data_cora.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_cora.val_mask].argmax(dim=1), data_cora.y[data_cora.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60f45ee-089c-4554-b9cd-84af0ed56376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP test accuracy for Cora dataset: 52.20%\n"
     ]
    }
   ],
   "source": [
    "# Test MLP model on Cora dataset    \n",
    "model_cora.eval()\n",
    "y_pred = model_cora(data_cora.x)\n",
    "acc = accuracy(y_pred[data_cora.test_mask].argmax(dim=1), data_cora.y[data_cora.test_mask])\n",
    "print(f'\\nMLP test accuracy for Cora dataset: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa3415-02c1-4072-9290-eb5823a19d22",
   "metadata": {},
   "source": [
    "## Repeat the process for the Facebook Page-Page dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de019e45-c618-4057-a3e6-cf3fc060eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fb = MLP(dataset_facebook.num_features, 16, dataset_facebook.num_classes)\n",
    "model_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bd314c-6285-4e85-869f-f03391bdd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.455 | Train Acc: 17.34%| Val Loss: 1.46 | Val Acc: 18.46%\n",
      "Epoch  20 | Train Loss: 0.836 | Train Acc: 67.44%| Val Loss: 0.84 | Val Acc: 65.88%\n",
      "Epoch  40 | Train Loss: 0.640 | Train Acc: 75.01%| Val Loss: 0.66 | Val Acc: 73.94%\n",
      "Epoch  60 | Train Loss: 0.588 | Train Acc: 76.84%| Val Loss: 0.62 | Val Acc: 75.84%\n",
      "Epoch  80 | Train Loss: 0.566 | Train Acc: 77.49%| Val Loss: 0.60 | Val Acc: 76.19%\n",
      "Epoch 100 | Train Loss: 0.553 | Train Acc: 77.93%| Val Loss: 0.60 | Val Acc: 76.24%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model on Facebook Page-Page dataset\n",
    "optimizer = torch.optim.Adam(model_fb.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "model_fb.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_fb(data_facebook.x)\n",
    "    train_loss = criterion(y_pred[data_facebook.train_mask], data_facebook.y[data_facebook.train_mask])\n",
    "    train_acc = accuracy(y_pred[data_facebook.train_mask].argmax(dim=1), data_facebook.y[data_facebook.train_mask])\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_facebook.val_mask], data_facebook.y[data_facebook.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_facebook.val_mask].argmax(dim=1), data_facebook.y[data_facebook.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f45f96d6-7da9-4d67-89a5-6a4b928a0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP test accuracy for Facebook Page-Page dataset: 75.05%\n"
     ]
    }
   ],
   "source": [
    "# Test MLP model on Facebook Page-Page dataset   \n",
    "model_fb.eval()\n",
    "y_pred = model_fb(data_facebook.x)\n",
    "test_acc = accuracy(y_pred[data_facebook.test_mask].argmax(dim=1), data_facebook.y[data_facebook.test_mask])\n",
    "print(f'\\nMLP test accuracy for Facebook Page-Page dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7895901-2a4a-49ee-9e8e-5cf0abd46ac1",
   "metadata": {},
   "source": [
    "## Classifying nodes with vanilla graph neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fdbf100-3e3b-4e36-bd88-51b245f7d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Graph Linear Layer, similar to GCN\n",
    "class VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sparse.mm(adjacency, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd68cf3-de43-4ac6-8fce-5d73636f1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h) # as similar to nn.Linear(dim_in, dim_out)\n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
    "    \n",
    "    def forward(self, x, adjacency):\n",
    "        h = self.gnn1(x, adjacency)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gnn2(h, adjacency)\n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c21f8f-ffb7-4eb9-a252-85c903aa135d",
   "metadata": {},
   "source": [
    "### Vanilla GNN for Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fa4060-ea19-421c-9998-ceaec42990de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize Vanilla GNN for Cora dataset\n",
    "vanilla_gnn = VanillaGNN(dataset_cora.num_features, 16, dataset_cora.num_classes)\n",
    "print(vanilla_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba0db78-470f-4773-98fc-c58bfa034ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "adjacency = to_dense_adj(data_cora.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aeafa1b-1834-404c-a4ec-42ff81dbdb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 2.373 | Train Acc: 24.29%| Val Loss: 2.12 | Val Acc: 21.60%\n",
      "Epoch  20 | Train Loss: 0.128 | Train Acc: 100.00%| Val Loss: 1.43 | Val Acc: 71.20%\n",
      "Epoch  40 | Train Loss: 0.020 | Train Acc: 100.00%| Val Loss: 2.00 | Val Acc: 73.60%\n",
      "Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00%| Val Loss: 2.19 | Val Acc: 73.80%\n",
      "Epoch  80 | Train Loss: 0.004 | Train Acc: 100.00%| Val Loss: 2.25 | Val Acc: 73.60%\n",
      "Epoch 100 | Train Loss: 0.003 | Train Acc: 100.00%| Val Loss: 2.27 | Val Acc: 74.00%\n"
     ]
    }
   ],
   "source": [
    "# Train VanillaGNN model on Cora dataset\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vanilla_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "vanilla_gnn.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = vanilla_gnn(data_cora.x, adjacency)\n",
    "    train_loss = criterion(y_pred[data_cora.train_mask], data_cora.y[data_cora.train_mask])\n",
    "    train_acc = accuracy(y_pred[data_cora.train_mask].argmax(dim=1), data_cora.y[data_cora.train_mask])\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_cora.val_mask], data_cora.y[data_cora.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_cora.val_mask].argmax(dim=1), data_cora.y[data_cora.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d6d7a9-21c4-43d0-bfdf-844f2b316d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vanilla GNN test accuracy for Cora dataset: 75.10%\n"
     ]
    }
   ],
   "source": [
    "# Test VanillaGNN model on Cora dataset\n",
    "vanilla_gnn.eval()\n",
    "y_pred = vanilla_gnn(data_cora.x, adjacency)\n",
    "test_acc = accuracy(y_pred[data_cora.test_mask].argmax(dim=1), data_cora.y[data_cora.test_mask])\n",
    "print(f'\\nVanilla GNN test accuracy for Cora dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c954c4d-9954-4bab-8d74-719bc9153f3b",
   "metadata": {},
   "source": [
    "### Vanilla GNN for Facebook Page-Page dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cec25cd-40d8-4208-84f8-5b81a77a8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=128, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize Vanilla GNN for Facebook dataset\n",
    "vanilla_gnn = VanillaGNN(dataset_facebook.num_features, 16, dataset_facebook.num_classes)\n",
    "print(vanilla_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39180e84-c138-4ed3-996e-27e8785f728e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency = to_dense_adj(data_facebook.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f982dff9-bc49-4e70-a57a-7a5cf98beb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 64.449 | Train Acc: 32.49%| Val Loss: 63.00 | Val Acc: 31.77%\n",
      "Epoch  20 | Train Loss: 6.214 | Train Acc: 77.75%| Val Loss: 3.97 | Val Acc: 78.94%\n",
      "Epoch  40 | Train Loss: 2.271 | Train Acc: 82.41%| Val Loss: 1.56 | Val Acc: 83.19%\n",
      "Epoch  60 | Train Loss: 1.334 | Train Acc: 83.00%| Val Loss: 0.97 | Val Acc: 82.44%\n",
      "Epoch  80 | Train Loss: 0.874 | Train Acc: 83.41%| Val Loss: 0.71 | Val Acc: 83.59%\n",
      "Epoch 100 | Train Loss: 0.699 | Train Acc: 83.73%| Val Loss: 0.61 | Val Acc: 84.14%\n"
     ]
    }
   ],
   "source": [
    "# Train VanillaGNN model on Facebook Page-Page dataset\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vanilla_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "vanilla_gnn.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = vanilla_gnn(data_facebook.x, adjacency)\n",
    "    train_loss = criterion(y_pred[data_facebook.train_mask], data_facebook.y[data_facebook.train_mask])\n",
    "    train_acc = accuracy(y_pred[data_facebook.train_mask].argmax(dim=1), data_facebook.y[data_facebook.train_mask])\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_facebook.val_mask], data_facebook.y[data_facebook.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_facebook.val_mask].argmax(dim=1), data_facebook.y[data_facebook.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132081b4-cf89-4a4b-9030-5234ca379fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vanilla GNN test accuracy for Facebook Page-Page dataset: 83.27%\n"
     ]
    }
   ],
   "source": [
    "# Test VanillaGNN model on Facebook Page-Page dataset\n",
    "vanilla_gnn.eval()\n",
    "y_pred = vanilla_gnn(data_facebook.x, adjacency)\n",
    "test_acc = accuracy(y_pred[data_facebook.test_mask].argmax(dim=1), data_facebook.y[data_facebook.test_mask])\n",
    "print(f'\\nVanilla GNN test accuracy for Facebook Page-Page dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af57e93-5bb5-41d5-9d82-60d0a6d893ee",
   "metadata": {},
   "source": [
    "## Graph Convolutional Networks (GCN)\n",
    "\n",
    "If we look at our Graph Linear layer, we donâ€™t take into account the difference in the number of neighbors. Our layer consists of a simple sum without any normalization coefficient. Imagine that node 1 has 1,000 neighbors and node 2 only has 1: the embedding $â„Ž_{1}$ will have much larger values than $â„Ž_{2}$. This becomes an issue if we want to compare these embeddings. How are we supposed to make meaningful comparisons when their values are so vastly different? Fortunately, there is a simple solution: dividing the embedding by the number of neighbors.\n",
    "\n",
    "Kipf and Welling noticed that features from nodes with a lot of neighbors spread very easily, unlike features from more isolated nodes. In the original GCN paper, the authors proposed a hybrid normalization to counterbalance this effect. In practice, they assign higher weights to nodes with few neighbors using the following formula:\n",
    "\n",
    "$H=\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}^{T}\\tilde{D}^{-\\frac{1}{2}}XW^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ef90767-ad17-480c-9b3d-28394b82a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25af4a47-8cf3-4deb-a718-5d1a91e5868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 5., ..., 1., 4., 4.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees = degree(data_cora.edge_index[0]).numpy()\n",
    "degrees # degree per node, i.e., 2708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbaf68c9-4aa3-4e24-b771-5da94bcf3e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 583,\n",
       "         3.0: 553,\n",
       "         1.0: 485,\n",
       "         4.0: 389,\n",
       "         5.0: 281,\n",
       "         6.0: 131,\n",
       "         7.0: 82,\n",
       "         8.0: 57,\n",
       "         10.0: 26,\n",
       "         9.0: 25,\n",
       "         12.0: 18,\n",
       "         11.0: 14,\n",
       "         17.0: 8,\n",
       "         16.0: 7,\n",
       "         14.0: 6,\n",
       "         15.0: 6,\n",
       "         19.0: 5,\n",
       "         13.0: 5,\n",
       "         21.0: 3,\n",
       "         18.0: 3,\n",
       "         23.0: 3,\n",
       "         32.0: 2,\n",
       "         30.0: 2,\n",
       "         36.0: 1,\n",
       "         78.0: 1,\n",
       "         33.0: 1,\n",
       "         29.0: 1,\n",
       "         34.0: 1,\n",
       "         26.0: 1,\n",
       "         168.0: 1,\n",
       "         22.0: 1,\n",
       "         42.0: 1,\n",
       "         74.0: 1,\n",
       "         44.0: 1,\n",
       "         31.0: 1,\n",
       "         65.0: 1,\n",
       "         40.0: 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = Counter(degrees) # counts the frequency of degrees (histogram) as a dictionary\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff3eafe-50ec-4fe1-a440-245da7c14e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "plt.bar(numbers.keys(), numbers.values())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2767e62-543e-43b7-912d-af587e460e60",
   "metadata": {},
   "source": [
    "This distribution looks exponential with a heavy tail: it ranges from 1 neighbor (485 nodes) to 168\n",
    "neighbors (1 node)! This is exactly the kind of dataset where we want a normalization process to\n",
    "consider this disbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b894d61d-36d6-4906-b4dc-fe276cd10b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 2658,\n",
       "         2.0: 2307,\n",
       "         3.0: 1843,\n",
       "         4.0: 1516,\n",
       "         5.0: 1359,\n",
       "         6.0: 1114,\n",
       "         7.0: 974,\n",
       "         8.0: 811,\n",
       "         9.0: 731,\n",
       "         10.0: 618,\n",
       "         11.0: 555,\n",
       "         12.0: 494,\n",
       "         13.0: 452,\n",
       "         14.0: 391,\n",
       "         15.0: 380,\n",
       "         17.0: 348,\n",
       "         16.0: 333,\n",
       "         18.0: 316,\n",
       "         19.0: 265,\n",
       "         20.0: 264,\n",
       "         21.0: 233,\n",
       "         22.0: 227,\n",
       "         23.0: 213,\n",
       "         25.0: 200,\n",
       "         24.0: 193,\n",
       "         26.0: 192,\n",
       "         29.0: 151,\n",
       "         27.0: 149,\n",
       "         28.0: 145,\n",
       "         31.0: 132,\n",
       "         33.0: 130,\n",
       "         30.0: 127,\n",
       "         32.0: 112,\n",
       "         35.0: 107,\n",
       "         36.0: 107,\n",
       "         34.0: 102,\n",
       "         37.0: 89,\n",
       "         38.0: 85,\n",
       "         43.0: 76,\n",
       "         40.0: 74,\n",
       "         42.0: 70,\n",
       "         39.0: 70,\n",
       "         44.0: 69,\n",
       "         41.0: 67,\n",
       "         45.0: 59,\n",
       "         51.0: 54,\n",
       "         53.0: 53,\n",
       "         48.0: 52,\n",
       "         47.0: 51,\n",
       "         46.0: 49,\n",
       "         50.0: 48,\n",
       "         49.0: 45,\n",
       "         62.0: 41,\n",
       "         59.0: 38,\n",
       "         60.0: 37,\n",
       "         57.0: 37,\n",
       "         55.0: 36,\n",
       "         56.0: 36,\n",
       "         52.0: 35,\n",
       "         54.0: 34,\n",
       "         61.0: 33,\n",
       "         69.0: 32,\n",
       "         67.0: 29,\n",
       "         58.0: 27,\n",
       "         64.0: 27,\n",
       "         68.0: 25,\n",
       "         65.0: 22,\n",
       "         66.0: 21,\n",
       "         71.0: 20,\n",
       "         70.0: 19,\n",
       "         73.0: 19,\n",
       "         63.0: 19,\n",
       "         76.0: 19,\n",
       "         74.0: 19,\n",
       "         83.0: 18,\n",
       "         75.0: 16,\n",
       "         72.0: 15,\n",
       "         94.0: 13,\n",
       "         78.0: 13,\n",
       "         77.0: 13,\n",
       "         87.0: 13,\n",
       "         90.0: 13,\n",
       "         99.0: 13,\n",
       "         81.0: 12,\n",
       "         88.0: 12,\n",
       "         86.0: 12,\n",
       "         80.0: 11,\n",
       "         105.0: 11,\n",
       "         112.0: 11,\n",
       "         79.0: 10,\n",
       "         89.0: 10,\n",
       "         104.0: 10,\n",
       "         92.0: 9,\n",
       "         84.0: 9,\n",
       "         93.0: 8,\n",
       "         97.0: 8,\n",
       "         106.0: 8,\n",
       "         82.0: 8,\n",
       "         85.0: 8,\n",
       "         101.0: 8,\n",
       "         96.0: 7,\n",
       "         121.0: 7,\n",
       "         107.0: 7,\n",
       "         116.0: 7,\n",
       "         91.0: 7,\n",
       "         120.0: 7,\n",
       "         114.0: 6,\n",
       "         117.0: 5,\n",
       "         102.0: 5,\n",
       "         122.0: 5,\n",
       "         108.0: 5,\n",
       "         100.0: 5,\n",
       "         138.0: 5,\n",
       "         109.0: 5,\n",
       "         142.0: 4,\n",
       "         110.0: 4,\n",
       "         115.0: 4,\n",
       "         141.0: 4,\n",
       "         95.0: 4,\n",
       "         125.0: 4,\n",
       "         113.0: 4,\n",
       "         145.0: 4,\n",
       "         148.0: 4,\n",
       "         134.0: 3,\n",
       "         133.0: 3,\n",
       "         111.0: 3,\n",
       "         177.0: 3,\n",
       "         135.0: 3,\n",
       "         98.0: 3,\n",
       "         127.0: 3,\n",
       "         118.0: 3,\n",
       "         201.0: 3,\n",
       "         132.0: 3,\n",
       "         144.0: 3,\n",
       "         156.0: 3,\n",
       "         103.0: 3,\n",
       "         140.0: 3,\n",
       "         129.0: 3,\n",
       "         155.0: 3,\n",
       "         222.0: 3,\n",
       "         146.0: 3,\n",
       "         123.0: 3,\n",
       "         143.0: 3,\n",
       "         131.0: 3,\n",
       "         119.0: 3,\n",
       "         174.0: 2,\n",
       "         229.0: 2,\n",
       "         226.0: 2,\n",
       "         139.0: 2,\n",
       "         275.0: 2,\n",
       "         126.0: 2,\n",
       "         181.0: 2,\n",
       "         214.0: 2,\n",
       "         193.0: 2,\n",
       "         182.0: 2,\n",
       "         257.0: 2,\n",
       "         124.0: 2,\n",
       "         199.0: 2,\n",
       "         330.0: 2,\n",
       "         183.0: 2,\n",
       "         147.0: 2,\n",
       "         167.0: 2,\n",
       "         288.0: 2,\n",
       "         236.0: 2,\n",
       "         188.0: 2,\n",
       "         151.0: 1,\n",
       "         244.0: 1,\n",
       "         380.0: 1,\n",
       "         153.0: 1,\n",
       "         233.0: 1,\n",
       "         150.0: 1,\n",
       "         504.0: 1,\n",
       "         260.0: 1,\n",
       "         408.0: 1,\n",
       "         203.0: 1,\n",
       "         137.0: 1,\n",
       "         166.0: 1,\n",
       "         216.0: 1,\n",
       "         240.0: 1,\n",
       "         333.0: 1,\n",
       "         149.0: 1,\n",
       "         196.0: 1,\n",
       "         225.0: 1,\n",
       "         162.0: 1,\n",
       "         178.0: 1,\n",
       "         387.0: 1,\n",
       "         169.0: 1,\n",
       "         351.0: 1,\n",
       "         136.0: 1,\n",
       "         171.0: 1,\n",
       "         191.0: 1,\n",
       "         290.0: 1,\n",
       "         338.0: 1,\n",
       "         364.0: 1,\n",
       "         168.0: 1,\n",
       "         212.0: 1,\n",
       "         468.0: 1,\n",
       "         370.0: 1,\n",
       "         341.0: 1,\n",
       "         158.0: 1,\n",
       "         256.0: 1,\n",
       "         328.0: 1,\n",
       "         194.0: 1,\n",
       "         172.0: 1,\n",
       "         157.0: 1,\n",
       "         234.0: 1,\n",
       "         650.0: 1,\n",
       "         326.0: 1,\n",
       "         375.0: 1,\n",
       "         298.0: 1,\n",
       "         163.0: 1,\n",
       "         266.0: 1,\n",
       "         709.0: 1,\n",
       "         237.0: 1,\n",
       "         220.0: 1,\n",
       "         170.0: 1,\n",
       "         218.0: 1,\n",
       "         152.0: 1,\n",
       "         217.0: 1,\n",
       "         296.0: 1,\n",
       "         280.0: 1,\n",
       "         448.0: 1,\n",
       "         185.0: 1,\n",
       "         678.0: 1,\n",
       "         189.0: 1,\n",
       "         128.0: 1,\n",
       "         241.0: 1,\n",
       "         320.0: 1,\n",
       "         417.0: 1,\n",
       "         224.0: 1,\n",
       "         195.0: 1,\n",
       "         659.0: 1,\n",
       "         205.0: 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same process is repeated for the Facebook Page-Page dataset\n",
    "degrees = degree(data_facebook.edge_index[0]).numpy() # degree per node, i.e., 22470\n",
    "numbers = Counter(degrees)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72cded7d-a68e-4ed1-a537-883e79dc0a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 709)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(min(numbers)), int(max(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d37cb6c6-fd8b-44b4-9972-e79629f11bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5+ElEQVR4nO3de3RU1cH+8WdIhuFiCATMTSOkCAgG5VYhqFwEAlREiku02CiIoK9cBbwALxK8cLEt0AallCKgSPFtBasVA+EiihGogRSCMQUFBSVGISTcTALs3x/+OIshATI4yZDs72etWWb22XPOfhLAZ505Z+IyxhgBAABYrFqgFwAAABBoFCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOsFB3oBlcWZM2f07bffKiQkRC6XK9DLAQAAZWCM0dGjRxUdHa1q1S58HohCVEbffvutYmJiAr0MAABwGfbv369rr732gtspRGUUEhIi6advaJ06dfy23+LiYq1Zs0YJCQlyu91+229lYXN+m7NLdue3ObtEfpvzByJ7QUGBYmJinP+PXwiFqIzOvk1Wp04dvxeiWrVqqU6dOtb9xZDszm9zdsnu/DZnl8hvc/5AZr/U5S5cVA0AAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FCAAAWC+ghWj69On65S9/qZCQEIWHh6tfv37Kzs72mjNo0CC5XC6vR4cOHbzmFBYWauTIkWrQoIFq166tvn376sCBA15z8vLylJiYqNDQUIWGhioxMVFHjhwp74gAAKASCGgh2rhxo4YPH67NmzcrNTVVp06dUkJCgo4fP+41r1evXjp48KDzWLVqldf2MWPGaOXKlVq+fLk2bdqkY8eOqU+fPjp9+rQzZ+DAgcrIyFBKSopSUlKUkZGhxMTECskJAACubMGBPHhKSorX80WLFik8PFzp6enq1KmTM+7xeBQZGVnqPvLz87Vw4UK9/vrr6t69uyRp6dKliomJ0dq1a9WzZ09lZWUpJSVFmzdvVvv27SVJCxYsUHx8vLKzs9WsWbNySggAACqDgBai8+Xn50uSwsLCvMY/+OADhYeHq27duurcubNefPFFhYeHS5LS09NVXFyshIQEZ350dLTi4uKUlpamnj176pNPPlFoaKhThiSpQ4cOCg0NVVpaWqmFqLCwUIWFhc7zgoICSVJxcbGKi4v9lvnsvvy5z8rE5vw2Z5fszm9zdon8NucPRPayHuuKKUTGGI0dO1a33Xab4uLinPHevXvr3nvvVcOGDbV3715NnjxZd9xxh9LT0+XxeJSTk6Pq1aurXr16XvuLiIhQTk6OJCknJ8cpUOcKDw935pxv+vTpmjp1aonxNWvWqFatWj8naqlSU1P9vs/KxOb8NmeX7M5vc3aJ/Dbnr8jsJ06cKNO8K6YQjRgxQjt27NCmTZu8xu+77z7n67i4OLVr104NGzbUe++9p/79+19wf8YYuVwu5/m5X19ozrkmTJigsWPHOs8LCgoUExOjhIQE1alTp8y5LqW4uFipqanq0aOH3G633/ZbWdic3+bskt35bc4ukd/m/IHIfvYdnku5IgrRyJEj9c477+jDDz/Utddee9G5UVFRatiwoXbv3i1JioyMVFFRkfLy8rzOEuXm5qpjx47OnO+++67Evr7//ntFRESUehyPxyOPx1Ni3O12l8sPsbz2W1nYnN/m7JLd+W3OLpHf5vwVmb2sxwnoXWbGGI0YMUIrVqzQ+vXrFRsbe8nXHDp0SPv371dUVJQkqW3btnK73V6n3w4ePKjMzEynEMXHxys/P19bt2515mzZskX5+fnOHAAAYK+AniEaPny4li1bpn/+858KCQlxrucJDQ1VzZo1dezYMSUlJemee+5RVFSU9u3bp4kTJ6pBgwb69a9/7cwdMmSIxo0bp/r16yssLEzjx49Xy5YtnbvOmjdvrl69emno0KGaP3++JGnYsGHq06cPd5gBAIDAFqJ58+ZJkrp06eI1vmjRIg0aNEhBQUHauXOnXnvtNR05ckRRUVHq2rWr3nzzTYWEhDjzZ8+ereDgYA0YMEAnT55Ut27dtHjxYgUFBTlz3njjDY0aNcq5G61v376aO3du+YcEAABXvIAWImPMRbfXrFlTq1evvuR+atSooeTkZCUnJ19wTlhYmJYuXerzGgEAQNXH7zIDAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFgvoIVo+vTp+uUvf6mQkBCFh4erX79+ys7O9ppjjFFSUpKio6NVs2ZNdenSRbt27fKaU1hYqJEjR6pBgwaqXbu2+vbtqwMHDnjNycvLU2JiokJDQxUaGqrExEQdOXKkvCMCAIBKIKCFaOPGjRo+fLg2b96s1NRUnTp1SgkJCTp+/Lgz56WXXtKsWbM0d+5c/fvf/1ZkZKR69Oiho0ePOnPGjBmjlStXavny5dq0aZOOHTumPn366PTp086cgQMHKiMjQykpKUpJSVFGRoYSExMrNC8AALgyBQfy4CkpKV7PFy1apPDwcKWnp6tTp04yxmjOnDmaNGmS+vfvL0lasmSJIiIitGzZMj366KPKz8/XwoUL9frrr6t79+6SpKVLlyomJkZr165Vz549lZWVpZSUFG3evFnt27eXJC1YsEDx8fHKzs5Ws2bNKjY4AAC4ogS0EJ0vPz9fkhQWFiZJ2rt3r3JycpSQkODM8Xg86ty5s9LS0vToo48qPT1dxcXFXnOio6MVFxentLQ09ezZU5988olCQ0OdMiRJHTp0UGhoqNLS0kotRIWFhSosLHSeFxQUSJKKi4tVXFzst8xn9+XPfVYmNue3Obtkd36bs0vktzl/ILKX9VhXTCEyxmjs2LG67bbbFBcXJ0nKycmRJEVERHjNjYiI0FdffeXMqV69uurVq1diztnX5+TkKDw8vMQxw8PDnTnnmz59uqZOnVpifM2aNapVq5aP6S4tNTXV7/usTGzOb3N2ye78NmeXyG9z/orMfuLEiTLNu2IK0YgRI7Rjxw5t2rSpxDaXy+X13BhTYux8588pbf7F9jNhwgSNHTvWeV5QUKCYmBglJCSoTp06Fz22L4qLi5WamqoePXrI7Xb7bb+Vhc35bc4u2Z3f5uwS+W3OH4jsZ9/huZQrohCNHDlS77zzjj788ENde+21znhkZKSkn87wREVFOeO5ubnOWaPIyEgVFRUpLy/P6yxRbm6uOnbs6Mz57rvvShz3+++/L3H26SyPxyOPx1Ni3O12l8sPsbz2W1nYnN/m7JLd+W3OLpHf5vwVmb2sxwnoXWbGGI0YMUIrVqzQ+vXrFRsb67U9NjZWkZGRXqfWioqKtHHjRqfstG3bVm6322vOwYMHlZmZ6cyJj49Xfn6+tm7d6szZsmWL8vPznTkAAMBeAT1DNHz4cC1btkz//Oc/FRIS4lzPExoaqpo1a8rlcmnMmDGaNm2amjRpoiZNmmjatGmqVauWBg4c6MwdMmSIxo0bp/r16yssLEzjx49Xy5YtnbvOmjdvrl69emno0KGaP3++JGnYsGHq06cPd5gBAIDAFqJ58+ZJkrp06eI1vmjRIg0aNEiS9NRTT+nkyZN6/PHHlZeXp/bt22vNmjUKCQlx5s+ePVvBwcEaMGCATp48qW7dumnx4sUKCgpy5rzxxhsaNWqUczda3759NXfu3PINCAAAKoWAFiJjzCXnuFwuJSUlKSkp6YJzatSooeTkZCUnJ19wTlhYmJYuXXo5ywQAAFUcv8sMAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD2/FKIjR474YzcAAAAB4XMhmjlzpt58803n+YABA1S/fn1dc801+s9//uPXxQEAAFQEnwvR/PnzFRMTI0lKTU1Vamqq3n//ffXu3VtPPvmk3xcIAABQ3oJ9fcHBgwedQvSvf/1LAwYMUEJCgho1aqT27dv7fYEAAADlzeczRPXq1dP+/fslSSkpKerevbskyRij06dP+3d1AAAAFcDnM0T9+/fXwIED1aRJEx06dEi9e/eWJGVkZOj666/3+wIBAADKm8+FaPbs2WrUqJH279+vl156SVdddZWkn95Ke/zxx/2+QAAAgPLmcyFyu90aP358ifExY8b4Yz0AAAAV7rI+h+j111/XbbfdpujoaH311VeSpDlz5uif//ynXxcHAABQEXwuRPPmzdPYsWPVu3dvHTlyxLmQum7dupozZ46/1wcAAFDufC5EycnJWrBggSZNmqSgoCBnvF27dtq5c6dfFwcAAFARfC5Ee/fuVevWrUuMezweHT9+3C+LAgAAqEg+F6LY2FhlZGSUGH///ffVokULf6wJAACgQvl8l9mTTz6p4cOH68cff5QxRlu3btXf/vY3TZ8+XX/961/LY40AAADlyudCNHjwYJ06dUpPPfWUTpw4oYEDB+qaa67RH//4R91///3lsUYAAIBy5XMhkqShQ4dq6NCh+uGHH3TmzBmFh4f7e10AAAAV5rIK0VkNGjTw1zoAAAACpkyFqHXr1nK5XGXa4bZt237WggAAACpamQpRv379nK9//PFHvfLKK2rRooXi4+MlSZs3b9auXbv4XWYAAKBSKlMhmjJlivP1I488olGjRun5558vMWf//v3+XR0AAEAF8PlziP7+97/rwQcfLDH+29/+Vm+99ZZfFgUAAFCRfC5ENWvW1KZNm0qMb9q0STVq1PDLogAAACqSz3eZjRkzRv/zP/+j9PR0dejQQdJP1xC9+uqrevbZZ/2+QAAAgPLmcyF65pln9Itf/EJ//OMftWzZMklS8+bNtXjxYg0YMMDvCwQAAChvl/U5RAMGDKD8AACAKuOyP5gxPT1dWVlZcrlcatGihVq3bu3PdQEAAFQYnwtRbm6u7r//fn3wwQeqW7eujDHKz89X165dtXz5cl199dXlsU4AAIBy4/NdZiNHjlRBQYF27dqlw4cPKy8vT5mZmSooKNCoUaPKY40AAADlyuczRCkpKVq7dq2aN2/ujLVo0UIvv/yyEhIS/Lo4AACAiuDzGaIzZ87I7XaXGHe73Tpz5oxfFgUAAFCRfC5Ed9xxh0aPHq1vv/3WGfvmm2/0xBNPqFu3bn5dHAAAQEXwuRDNnTtXR48eVaNGjdS4cWNdf/31io2N1dGjR5WcnFweawQAAChXPl9DFBMTo23btik1NVWff/65jDFq0aKFunfvXh7rAwAAKHeX/TlEPXr0UI8ePfy5FgAAgIC4rEK0bt06rVu3Trm5uSUupH711Vf9sjAAAICK4nMhmjp1qp577jm1a9dOUVFRcrlc5bEuAACACuNzIfrzn/+sxYsXKzExsTzWAwAAUOF8vsusqKhIHTt2LI+1AAAABITPheiRRx7RsmXLymMtAAAAAeHzW2Y//vij/vKXv2jt2rW66aabSnxq9axZs/y2OAAAgIrg8xmiHTt2qFWrVqpWrZoyMzO1fft255GRkeHTvj788EPdddddio6Olsvl0ttvv+21fdCgQXK5XF6PDh06eM0pLCzUyJEj1aBBA9WuXVt9+/bVgQMHvObk5eUpMTFRoaGhCg0NVWJioo4cOeJrdAAAUEX5fIZow4YNfjv48ePHdfPNN2vw4MG65557Sp3Tq1cvLVq0yHlevXp1r+1jxozRu+++q+XLl6t+/foaN26c+vTpo/T0dAUFBUmSBg4cqAMHDiglJUWSNGzYMCUmJurdd9/1WxYAAFB5XfYHM/pD79691bt374vO8Xg8ioyMLHVbfn6+Fi5cqNdff935pOylS5cqJiZGa9euVc+ePZWVlaWUlBRt3rxZ7du3lyQtWLBA8fHxys7OVrNmzfwb6mdo9Mx72jfjzkAvAwAA6wS0EJXFBx98oPDwcNWtW1edO3fWiy++qPDwcElSenq6iouLlZCQ4MyPjo5WXFyc0tLS1LNnT33yyScKDQ11ypAkdejQQaGhoUpLS7tgISosLFRhYaHzvKCgQJJUXFys4uJiv+U7u6/i4mJ5goxf910ZnJvfNjZnl+zOb3N2ifw25w9E9rIe64ouRL1799a9996rhg0bau/evZo8ebLuuOMOpaeny+PxKCcnR9WrV1e9evW8XhcREaGcnBxJUk5OjlOgzhUeHu7MKc306dM1derUEuNr1qxRrVq1fmayklJTU/XSLdKqVav8vu/KIDU1NdBLCBibs0t257c5u0R+m/NXZPYTJ06Uad4VXYjuu+8+5+u4uDi1a9dODRs21Hvvvaf+/ftf8HXGGK9P0C7t07TPn3O+CRMmaOzYsc7zgoICxcTEKCEhQXXq1PE1ygUVFxcrNTVVPXr0UOsX1yszqaff9l0ZnJv//DsWqzqbs0t257c5u0R+m/MHIvvZd3gupUyFqE2bNlq3bp3q1aun5557TuPHjy+XsySXEhUVpYYNG2r37t2SpMjISBUVFSkvL8/rLFFubq7z4ZGRkZH67rvvSuzr+++/V0RExAWP5fF45PF4Soy73e5y+SG63W4VnnZZ95fjrPL6vlYGNmeX7M5vc3aJ/Dbnr8jsZT1OmW67z8rK0vHjxyX99LvMjh07dvkr+xkOHTqk/fv3KyoqSpLUtm1bud1ur1NvBw8eVGZmplOI4uPjlZ+fr61btzpztmzZovz8fD5xGwAASCrjGaJWrVpp8ODBuu2222SM0e9//3tdddVVpc599tlny3zwY8eOac+ePc7zvXv3KiMjQ2FhYQoLC1NSUpLuueceRUVFad++fZo4caIaNGigX//615Kk0NBQDRkyROPGjVP9+vUVFham8ePHq2XLls5dZ82bN1evXr00dOhQzZ8/X9JPt9336dPnirrDDAAABE6ZCtHixYs1ZcoU/etf/5LL5dL777+v4OCSL3W5XD4Vok8//VRdu3Z1np+9Zuehhx7SvHnztHPnTr322ms6cuSIoqKi1LVrV7355psKCQlxXjN79mwFBwdrwIABOnnypLp166bFixc7n0EkSW+88YZGjRrl3I3Wt29fzZ07t8zrBAAAVVuZClGzZs20fPlySVK1atW0bt26Uu/c8lWXLl1kjLng9tWrV19yHzVq1FBycrKSk5MvOCcsLExLly69rDUCAICqz+e7zM6cOVMe6wAAAAiYy7rt/osvvtCcOXOUlZUll8ul5s2ba/To0WrcuLG/1wcAAFDufP7lrqtXr1aLFi20detW3XTTTYqLi9OWLVt04403Wv0hUwAAoPLy+QzRM888oyeeeEIzZswoMf7000+rR48eflscAABARfD5DFFWVpaGDBlSYvzhhx/WZ5995pdFAQAAVCSfC9HVV1+tjIyMEuMZGRl+ufMMAACgovn8ltnQoUM1bNgwffnll+rYsaNcLpc2bdqkmTNnaty4ceWxRgAAgHLlcyGaPHmyQkJC9Ic//EETJkyQJEVHRyspKUmjRo3y+wIBAADKm8+FyOVy6YknntATTzyho0ePSpLXJ0cDAABUNpf1OURnUYQAAEBV4PNF1QAAAFUNhQgAAFiPQgQAAKznUyEqLi5W165d9d///re81gMAAFDhfCpEbrdbmZmZcrlc5bUeAACACufzW2YPPvigFi5cWB5rAQAACAifb7svKirSX//6V6Wmpqpdu3aqXbu21/ZZs2b5bXEAAAAVwedClJmZqTZt2khSiWuJeCsNAABURj4Xog0bNpTHOgAAAALmsm+737Nnj1avXq2TJ09KkowxflsUAABARfK5EB06dEjdunVT06ZN9atf/UoHDx6UJD3yyCP8tnsAAFAp+VyInnjiCbndbn399deqVauWM37fffcpJSXFr4sDAACoCD5fQ7RmzRqtXr1a1157rdd4kyZN9NVXX/ltYQAAABXF5zNEx48f9zozdNYPP/wgj8fjl0UBAABUJJ8LUadOnfTaa685z10ul86cOaPf/e536tq1q18XBwAAUBF8fsvsd7/7nbp06aJPP/1URUVFeuqpp7Rr1y4dPnxYH3/8cXmsEQAAoFz5fIaoRYsW2rFjh2655Rb16NFDx48fV//+/bV9+3Y1bty4PNYIAABQrnw+QyRJkZGRmjp1qr/XAgAAEBCXVYjy8vK0cOFCZWVlyeVyqXnz5ho8eLDCwsL8vT4AAIBy5/NbZhs3blRsbKz+9Kc/KS8vT4cPH9af/vQnxcbGauPGjeWxRgAAgHLl8xmi4cOHa8CAAZo3b56CgoIkSadPn9bjjz+u4cOHKzMz0++LBAAAKE8+nyH64osvNG7cOKcMSVJQUJDGjh2rL774wq+LAwAAqAg+F6I2bdooKyurxHhWVpZatWrljzUBAABUqDK9ZbZjxw7n61GjRmn06NHas2ePOnToIEnavHmzXn75Zc2YMaN8VgkAAFCOylSIWrVqJZfLJWOMM/bUU0+VmDdw4EDdd999/lsdAABABShTIdq7d295rwMAACBgylSIGjZsWN7rAAAACJjL+mDGb775Rh9//LFyc3N15swZr22jRo3yy8IAAAAqis+FaNGiRXrsscdUvXp11a9fXy6Xy9nmcrkoRAAAoNLxuRA9++yzevbZZzVhwgRVq+bzXfsAAABXHJ8bzYkTJ3T//fdThgAAQJXhc6sZMmSI/v73v5fHWgAAAALC57fMpk+frj59+iglJUUtW7aU2+322j5r1iy/LQ4AAKAi+FyIpk2bptWrV6tZs2aSVOKiagAAgMrG50I0a9Ysvfrqqxo0aFA5LAcAAKDi+XwNkcfj0a233loeawEAAAgInwvR6NGjlZycXB5rAQAACAif3zLbunWr1q9fr3/961+68cYbS1xUvWLFCr8tDgAAoCL4XIjq1q2r/v37l8daAAAAAuKyfnUHAABAVcLHTQMAAOv5fIYoNjb2op839OWXX/6sBQEAAFQ0nwvRmDFjvJ4XFxdr+/btSklJ0ZNPPumvdQEAAFQYnwvR6NGjSx1/+eWX9emnn/7sBQEAAFQ0v11D1Lt3b7311lv+2h0AAECF8Vsh+sc//qGwsDB/7Q4AAKDC+FyIWrdurTZt2jiP1q1bKyoqShMnTtTEiRN92teHH36ou+66S9HR0XK5XHr77be9thtjlJSUpOjoaNWsWVNdunTRrl27vOYUFhZq5MiRatCggWrXrq2+ffvqwIEDXnPy8vKUmJio0NBQhYaGKjExUUeOHPE1OgAAqKJ8voaoX79+Xs+rVaumq6++Wl26dNENN9zg076OHz+um2++WYMHD9Y999xTYvtLL72kWbNmafHixWratKleeOEF9ejRQ9nZ2QoJCZH000Xe7777rpYvX6769etr3Lhx6tOnj9LT0xUUFCRJGjhwoA4cOKCUlBRJ0rBhw5SYmKh3333X1/gAAKAK8rkQTZkyxW8H7927t3r37l3qNmOM5syZo0mTJjmfjL1kyRJFRERo2bJlevTRR5Wfn6+FCxfq9ddfV/fu3SVJS5cuVUxMjNauXauePXsqKytLKSkp2rx5s9q3by9JWrBggeLj45Wdna1mzZqVevzCwkIVFhY6zwsKCiT9dFddcXGx374HZ/dVXFwsT5Dx674rg3Pz28bm7JLd+W3OLpHf5vyByF7WY7mMMaac11ImLpdLK1eudM5Affnll2rcuLG2bdum1q1bO/Puvvtu1a1bV0uWLNH69evVrVs3HT58WPXq1XPm3HzzzerXr5+mTp2qV199VWPHji3xFlndunU1e/ZsDR48uNT1JCUlaerUqSXGly1bplq1av38wAAAoNydOHFCAwcOVH5+vurUqXPBeWU+Q1StWrWLfiCj9FOpOXXqVNlXeRE5OTmSpIiICK/xiIgIffXVV86c6tWre5Whs3POvj4nJ0fh4eEl9h8eHu7MKc2ECRM0duxY53lBQYFiYmKUkJBw0W+or4qLi5WamqoePXqo9YvrlZnU02/7rgzOzX/+Lwqu6mzOLtmd3+bsEvltzh+I7Gff4bmUMheilStXXnBbWlqakpOTVR4nm84vYcaYSxaz8+eUNv9S+/F4PPJ4PCXG3W53ufwQ3W63Ck+7rPvLcVZ5fV8rA5uzS3bntzm7RH6b81dk9rIep8yF6O677y4x9vnnn2vChAl699139cADD+j5558v+wovITIyUtJPZ3iioqKc8dzcXOesUWRkpIqKipSXl+d1lig3N1cdO3Z05nz33Xcl9v/999+XOPsEAADsdFmfQ/Ttt99q6NChuummm3Tq1CllZGRoyZIluu666/y2sNjYWEVGRio1NdUZKyoq0saNG52y07ZtW7ndbq85Bw8eVGZmpjMnPj5e+fn52rp1qzNny5Ytys/Pd+ZcaRo9816glwAAgFV8usssPz9f06ZNU3Jyslq1aqV169bp9ttvv+yDHzt2THv27HGe7927VxkZGQoLC9N1112nMWPGaNq0aWrSpImaNGmiadOmqVatWho4cKAkKTQ0VEOGDNG4ceNUv359hYWFafz48WrZsqVz11nz5s3Vq1cvDR06VPPnz5f00233ffr0ueAdZgAAwC5lLkQvvfSSZs6cqcjISP3tb38r9S00X3366afq2rWr8/zsRcwPPfSQFi9erKeeekonT57U448/rry8PLVv315r1qxxPoNIkmbPnq3g4GANGDBAJ0+eVLdu3bR48WLnM4gk6Y033tCoUaOUkJAgSerbt6/mzp37s9cPAACqhjIXomeeeUY1a9bU9ddfryVLlmjJkiWlzluxYkWZD96lS5eLXojtcrmUlJSkpKSkC86pUaOGkpOTlZycfME5YWFhWrp0aZnXBQAA7FLmQvTggw9e8u4uAACAyqjMhWjx4sXluAwAAIDA8dtvuwcAAKisKEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FKIrVKNn3gv0EgAAsAaFCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FKIrWKNn3gv0EgAAsAKFCAAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoUIAABYj0IEAACsRyECAADWu6ILUVJSklwul9cjMjLS2W6MUVJSkqKjo1WzZk116dJFu3bt8tpHYWGhRo4cqQYNGqh27drq27evDhw4UNFRAADAFeyKLkSSdOONN+rgwYPOY+fOnc62l156SbNmzdLcuXP173//W5GRkerRo4eOHj3qzBkzZoxWrlyp5cuXa9OmTTp27Jj69Omj06dPByIOAAC4AgUHegGXEhwc7HVW6CxjjObMmaNJkyapf//+kqQlS5YoIiJCy5Yt06OPPqr8/HwtXLhQr7/+urp37y5JWrp0qWJiYrR27Vr17NmzQrMAAIAr0xVfiHbv3q3o6Gh5PB61b99e06ZN0y9+8Qvt3btXOTk5SkhIcOZ6PB517txZaWlpevTRR5Wenq7i4mKvOdHR0YqLi1NaWtpFC1FhYaEKCwud5wUFBZKk4uJiFRcX+y3f2X0VFxfLE2Sc/56/vao6N79tbM4u2Z3f5uwS+W3OH4jsZT2WyxhjLj0tMN5//32dOHFCTZs21XfffacXXnhBn3/+uXbt2qXs7Gzdeuut+uabbxQdHe28ZtiwYfrqq6+0evVqLVu2TIMHD/YqNpKUkJCg2NhYzZ8//4LHTkpK0tSpU0uML1u2TLVq1fJfSAAAUG5OnDihgQMHKj8/X3Xq1LngvCv6DFHv3r2dr1u2bKn4+Hg1btxYS5YsUYcOHSRJLpfL6zXGmBJj5yvLnAkTJmjs2LHO84KCAsXExCghIeGi31BfFRcXKzU1VT169FDrF9crM6mn4pJWe83JTKq6b+2dm9/tdgd6ORXK5uyS3fltzi6R3+b8gch+9h2eS7miC9H5ateurZYtW2r37t3q16+fJCknJ0dRUVHOnNzcXEVEREiSIiMjVVRUpLy8PNWrV89rTseOHS96LI/HI4/HU2Lc7XaXyw/R7Xar8LTL+e/526q68vq+VgY2Z5fszm9zdon8NuevyOxlPc4Vf5fZuQoLC5WVlaWoqCjFxsYqMjJSqampzvaioiJt3LjRKTtt27aV2+32mnPw4EFlZmZeshABAAB7XNFniMaPH6+77rpL1113nXJzc/XCCy+ooKBADz30kFwul8aMGaNp06apSZMmatKkiaZNm6ZatWpp4MCBkqTQ0FANGTJE48aNU/369RUWFqbx48erZcuWzl1nAAAAV3QhOnDggH7zm9/ohx9+0NVXX60OHTpo8+bNatiwoSTpqaee0smTJ/X4448rLy9P7du315o1axQSEuLsY/bs2QoODtaAAQN08uRJdevWTYsXL1ZQUFCgYgEAgCvMFV2Ili9fftHtLpdLSUlJSkpKuuCcGjVqKDk5WcnJyX5eHQAAqCoq1TVEAAAA5YFCBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACwHoWokmj0zHuBXgIAAFUWhQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRAAAwHoUIgAAYD0KEQAAsB6FqJLhAxoBAPA/ChEAALAehQgAAFiPQgQAAKxHIQIAANajEAEAAOtRiAAAgPUoRJUQt94DAOBfFCIAAGA9ChEAALAehQgAAFiPQlRJcR0RAAD+QyECAADWoxABAADrUYgqMd42AwDAPyhEAADAehSiKoAzRQAA/DwUIgAAYD0KEQAAsB6FCAAAWI9CBAAArEchAgAA1qMQVSHcbQYAwOWhEFURlCEAAC4fhaiKoRgBAOA7ChEAALAehQgAAFiPQlQF8bYZAAC+oRBVUZQiAADKjkIEAACsRyGq4jhTBADApVGIAACA9YIDvQCUv/PPEu2bcWeAVgIAwJWJM0QAAMB6FCILcV0RAADeeMvMYryVBgDATzhDhIvibBIAwAacIYLjbPnZN+NOihAAwCpWnSF65ZVXFBsbqxo1aqht27b66KOPAr2kSuFsOaIkAQCqKmsK0ZtvvqkxY8Zo0qRJ2r59u26//Xb17t1bX3/9daCXVimcW4bOL0jnFyWKEwCgsrGmEM2aNUtDhgzRI488oubNm2vOnDmKiYnRvHnzAr20SulCpej84nT2cf7rLrZPAAAqmhXXEBUVFSk9PV3PPPOM13hCQoLS0tJKfU1hYaEKCwud5/n5+ZKkw4cPq7i42G9rKy4u1okTJ3To0CEFnzru/PdcZdlWmkBuu378/3n94Tp06JDaT1+n4P+/7SxPNaP/bX1GrSatUPAZl9c2SdoyoZvaT19X6vHO3bZlQjdJuuDz0l53ds5ZpY1dzNn5576utOOX9rUkdZq5Vv/b+owOHTokt9td5uNeag0/h7/2Uxbn/tm/3PyVlc3ZJfLbnD8Q2Y8ePSpJMsZcfKKxwDfffGMkmY8//thr/MUXXzRNmzYt9TVTpkwxknjw4MGDBw8eVeCxf//+i3YFK84QneVyubyeG2NKjJ01YcIEjR071nl+5swZHT58WPXr17/gay5HQUGBYmJitH//ftWpU8dv+60sbM5vc3bJ7vw2Z5fIb3P+QGQ3xujo0aOKjo6+6DwrClGDBg0UFBSknJwcr/Hc3FxFRESU+hqPxyOPx+M1Vrdu3fJaourUqWPdX4xz2Zzf5uyS3fltzi6R3+b8FZ09NDT0knOsuKi6evXqatu2rVJTU73GU1NT1bFjxwCtCgAAXCmsOEMkSWPHjlViYqLatWun+Ph4/eUvf9HXX3+txx57LNBLAwAAAWZNIbrvvvt06NAhPffcczp48KDi4uK0atUqNWzYMKDr8ng8mjJlSom352xhc36bs0t257c5u0R+m/NfydldxlzqPjQAAICqzYpriAAAAC6GQgQAAKxHIQIAANajEAEAAOtRiALolVdeUWxsrGrUqKG2bdvqo48+CvSS/OLDDz/UXXfdpejoaLlcLr399tte240xSkpKUnR0tGrWrKkuXbpo165dXnMKCws1cuRINWjQQLVr11bfvn114MCBCkxxeaZPn65f/vKXCgkJUXh4uPr166fs7GyvOVU5/7x583TTTTc5H7oWHx+v999/39lelbOfb/r06XK5XBozZowzVpXzJyUlyeVyeT0iIyOd7VU5uyR98803+u1vf6v69eurVq1aatWqldLT053tVTl/o0aNSvzsXS6Xhg8fLqkSZf95vyUMl2v58uXG7XabBQsWmM8++8yMHj3a1K5d23z11VeBXtrPtmrVKjNp0iTz1ltvGUlm5cqVXttnzJhhQkJCzFtvvWV27txp7rvvPhMVFWUKCgqcOY899pi55pprTGpqqtm2bZvp2rWrufnmm82pU6cqOI1vevbsaRYtWmQyMzNNRkaGufPOO811111njh075sypyvnfeecd895775ns7GyTnZ1tJk6caNxut8nMzDTGVO3s59q6datp1KiRuemmm8zo0aOd8aqcf8qUKebGG280Bw8edB65ubnO9qqc/fDhw6Zhw4Zm0KBBZsuWLWbv3r1m7dq1Zs+ePc6cqpw/NzfX6+eemppqJJkNGzYYYypPdgpRgNxyyy3mscce8xq74YYbzDPPPBOgFZWP8wvRmTNnTGRkpJkxY4Yz9uOPP5rQ0FDz5z//2RhjzJEjR4zb7TbLly935nzzzTemWrVqJiUlpcLW7g+5ublGktm4caMxxr78xhhTr14989e//tWa7EePHjVNmjQxqamppnPnzk4hqur5p0yZYm6++eZSt1X17E8//bS57bbbLri9quc/3+jRo03jxo3NmTNnKlV23jILgKKiIqWnpyshIcFrPCEhQWlpaQFaVcXYu3evcnJyvLJ7PB517tzZyZ6enq7i4mKvOdHR0YqLi6t035/8/HxJUlhYmCS78p8+fVrLly/X8ePHFR8fb0324cOH684771T37t29xm3Iv3v3bkVHRys2Nlb333+/vvzyS0lVP/s777yjdu3a6d5771V4eLhat26tBQsWONurev5zFRUVaenSpXr44YflcrkqVXYKUQD88MMPOn36dIlfLBsREVHiF9BWNWfzXSx7Tk6Oqlevrnr16l1wTmVgjNHYsWN12223KS4uTpId+Xfu3KmrrrpKHo9Hjz32mFauXKkWLVpYkX358uXatm2bpk+fXmJbVc/fvn17vfbaa1q9erUWLFignJwcdezYUYcOHary2b/88kvNmzdPTZo00erVq/XYY49p1KhReu211yRV/Z/9ud5++20dOXJEgwYNklS5slvzqzuuRC6Xy+u5MabEWFV1Odkr2/dnxIgR2rFjhzZt2lRiW1XO36xZM2VkZOjIkSN666239NBDD2njxo3O9qqaff/+/Ro9erTWrFmjGjVqXHBeVc3fu3dv5+uWLVsqPj5ejRs31pIlS9ShQwdJVTf7mTNn1K5dO02bNk2S1Lp1a+3atUvz5s3Tgw8+6MyrqvnPtXDhQvXu3VvR0dFe45UhO2eIAqBBgwYKCgoq0Xxzc3NLtOiq5uxdJxfLHhkZqaKiIuXl5V1wzpVu5MiReuedd7RhwwZde+21zrgN+atXr67rr79e7dq10/Tp03XzzTfrj3/8Y5XPnp6ertzcXLVt21bBwcEKDg7Wxo0b9ac//UnBwcHO+qtq/vPVrl1bLVu21O7du6v8zz4qKkotWrTwGmvevLm+/vprSXb8vZekr776SmvXrtUjjzzijFWm7BSiAKhevbratm2r1NRUr/HU1FR17NgxQKuqGLGxsYqMjPTKXlRUpI0bNzrZ27ZtK7fb7TXn4MGDyszMvOK/P8YYjRgxQitWrND69esVGxvrtb2q5y+NMUaFhYVVPnu3bt20c+dOZWRkOI927drpgQceUEZGhn7xi19U6fznKywsVFZWlqKioqr8z/7WW28t8fEa//3vf51fHl7V85+1aNEihYeH684773TGKlX2Crt8G17O3na/cOFC89lnn5kxY8aY2rVrm3379gV6aT/b0aNHzfbt28327duNJDNr1iyzfft25yMFZsyYYUJDQ82KFSvMzp07zW9+85tSb8G89tprzdq1a822bdvMHXfcUSluP/2f//kfExoaaj744AOv21BPnDjhzKnK+SdMmGA+/PBDs3fvXrNjxw4zceJEU61aNbNmzRpjTNXOXppz7zIzpmrnHzdunPnggw/Ml19+aTZv3mz69OljQkJCnH/TqnL2rVu3muDgYPPiiy+a3bt3mzfeeMPUqlXLLF261JlTlfMbY8zp06fNddddZ55++ukS2ypLdgpRAL388sumYcOGpnr16qZNmzbOrdmV3YYNG4ykEo+HHnrIGPPTLahTpkwxkZGRxuPxmE6dOpmdO3d67ePkyZNmxIgRJiwszNSsWdP06dPHfP311wFI45vScksyixYtcuZU5fwPP/yw82f66quvNt26dXPKkDFVO3tpzi9EVTn/2c+WcbvdJjo62vTv39/s2rXL2V6VsxtjzLvvvmvi4uKMx+MxN9xwg/nLX/7itb2q51+9erWRZLKzs0tsqyzZXcYYU3HnowAAAK48XEMEAACsRyECAADWoxABAADrUYgAAID1KEQAAMB6FCIAAGA9ChEAALAehQgAAFiPQgSgUmrUqJHmzJnj133u27dPLpdLGRkZft0vgCsfhQhAuRg0aJBcLpdmzJjhNf7222/L5XIFaFUAUDoKEYByU6NGDc2cOVN5eXmBXsoVpaioKNBLAHAeChGActO9e3dFRkZq+vTpF5331ltv6cYbb5TH41GjRo30hz/8wWt7bm6u7rrrLtWsWVOxsbF64403SuwjPz9fw4YNU3h4uOrUqaM77rhD//nPfy563K1bt6p169aqUaOG2rVrp+3bt5eY89lnn+lXv/qVrrrqKkVERCgxMVE//PCDs/3o0aN64IEHVLt2bUVFRWn27Nnq0qWLxowZ48xp1KiRXnjhBQ0aNEihoaEaOnSoJCktLU2dOnVSzZo1FRMTo1GjRun48ePO64qKivTUU0/pmmuuUe3atdW+fXt98MEHF80E4PJQiACUm6CgIE2bNk3Jyck6cOBAqXPS09M1YMAA3X///dq5c6eSkpI0efJkLV682JkzaNAg7du3T+vXr9c//vEPvfLKK8rNzXW2G2N05513KicnR6tWrVJ6erratGmjbt266fDhw6Ue9/jx4+rTp4+aNWum9PR0JSUlafz48V5zDh48qM6dO6tVq1b69NNPlZKSou+++04DBgxw5owdO1Yff/yx3nnnHaWmpuqjjz7Stm3bShzvd7/7neLi4pSenq7Jkydr586d6tmzp/r3768dO3bozTff1KZNmzRixAjnNYMHD9bHH3+s5cuXa8eOHbr33nvVq1cv7d69u0zffwA+MABQDh566CFz9913G2OM6dChg3n44YeNMcasXLnSnPtPz8CBA02PHj28Xvvkk0+aFi1aGGOMyc7ONpLM5s2bne1ZWVlGkpk9e7Yxxph169aZOnXqmB9//NFrP40bNzbz588vdX3z5883YWFh5vjx487YvHnzjCSzfft2Y4wxkydPNgkJCV6v279/v5FksrOzTUFBgXG73ebvf/+7s/3IkSOmVq1aZvTo0c5Yw4YNTb9+/bz2k5iYaIYNG+Y19tFHH5lq1aqZkydPmj179hiXy2W++eYbrzndunUzEyZMKDUTgMsXHNA2BsAKM2fO1B133KFx48aV2JaVlaW7777ba+zWW2/VnDlzdPr0aWVlZSk4OFjt2rVztt9www2qW7eu8zw9PV3Hjh1T/fr1vfZz8uRJffHFF6WuKSsrSzfffLNq1arljMXHx3vNSU9P14YNG3TVVVeVeP0XX3yhkydPqri4WLfccoszHhoaqmbNmpWYf+76z+57z549Xm//GWN05swZ7d27V5mZmTLGqGnTpl6vKywsLJETwM9HIQJQ7jp16qSePXtq4sSJGjRokNc2Y0yJu86MMSW+vtidaWfOnFFUVFSp19ecW5wudIyL7feuu+7SzJkzS2yLiopy3rq62PrPql27dol9P/rooxo1alSJudddd5127NihoKAgpaenKygoyGt7aQUNwM9DIQJQIWbMmKFWrVqVOOPRokULbdq0yWssLS1NTZs2VVBQkJo3b65Tp07p008/dc7EZGdn68iRI878Nm3aKCcnR8HBwWrUqFGZ1tOiRQu9/vrrOnnypGrWrClJ2rx5s9ecNm3a6K233lKjRo0UHFzyn8vGjRvL7XZr69atiomJkSQVFBRo9+7d6ty580WP36ZNG+3atUvXX399qdtbt26t06dPKzc3V7fffnuZMgG4fFxUDaBCtGzZUg888ICSk5O9xseNG6d169bp+eef13//+18tWbJEc+fOdS5wbtasmXr16qWhQ4dqy5YtSk9P1yOPPOKUGOmnu9ni4+PVr18/rV69Wvv27VNaWpr+93//V59++mmp6xk4cKCqVaumIUOG6LPPPtOqVav0+9//3mvO8OHDdfjwYf3mN7/R1q1b9eWXX2rNmjV6+OGHdfr0aYWEhOihhx7Sk08+qQ0bNmjXrl16+OGHVa1atUt+1tLTTz+tTz75RMOHD1dGRoZ2796td955RyNHjpQkNW3aVA888IAefPBBrVixQnv37tW///1vzZw5U6tWrfL5+w/g4ihEACrM888/X+LtpDZt2uj//u//tHz5csXFxenZZ5/Vc8895/XW2qJFixQTE6POnTurf//+zu31Z7lcLq1atUqdOnXSww8/rKZNm+r+++/Xvn37FBERUeparrrqKr377rv67LPP1Lp1a02aNKnEW2PR0dH6+OOPdfr0afXs2VNxcXEaPXq0QkNDVa3aT/98zpo1S/Hx8erTp4+6d++uW2+9Vc2bN1eNGjUu+r246aabtHHjRu3evVu33367WrdurcmTJysqKsor94MPPqhx48apWbNm6tu3r7Zs2eKcjQLgPy5TljfSAQBlcvz4cV1zzTX6wx/+oCFDhgR6OQDKiGuIAOBn2L59uz7//HPdcsstys/P13PPPSdJJe6cA3BloxABwM/0+9//XtnZ2apevbratm2rjz76SA0aNAj0sgD4gLfMAACA9bioGgAAWI9CBAAArEchAgAA1qMQAQAA61GIAACA9ShEAADAehQiAABgPQoRAACw3v8DaOQc8IpDQKYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "plt.bar(numbers.keys(), numbers.values())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812faed3-2fbf-41d8-be25-c12131769c76",
   "metadata": {},
   "source": [
    "This distribution of node degrees looks even more skewed, with a number of neighbors that ranges\n",
    "from 1 to 709. For the same reason, the Facebook Page-Page dataset is also a good case in which to\n",
    "apply a GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb36fdbc-8cdd-4121-a4aa-c356d05080d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ffdcf21-1fa9-4900-b16b-127f53f90af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53f90e-f704-4d63-96aa-76f1bebad8ec",
   "metadata": {},
   "source": [
    "### GCN for Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a81e3c-a32f-4532-ac38-ad3104d8b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(1433, 16)\n",
       "  (gcn2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_cora = GCN(dataset_cora.num_features, 16, dataset_cora.num_classes)\n",
    "gcn_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31fa5e3e-a25c-43b0-97fa-3173f89c7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss() # loss\n",
    "optimizer = torch.optim.Adam(gcn_cora.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13aec0b3-a471-498d-8095-25542b2dc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.938 | Train Acc: 15.00%| Val Loss: 1.94 | Val Acc: 15.00%\n",
      "Epoch  20 | Train Loss: 0.605 | Train Acc: 90.00%| Val Loss: 1.16 | Val Acc: 64.00%\n",
      "Epoch  40 | Train Loss: 0.134 | Train Acc: 100.00%| Val Loss: 0.85 | Val Acc: 75.20%\n",
      "Epoch  60 | Train Loss: 0.045 | Train Acc: 100.00%| Val Loss: 0.77 | Val Acc: 76.00%\n",
      "Epoch  80 | Train Loss: 0.029 | Train Acc: 100.00%| Val Loss: 0.74 | Val Acc: 77.00%\n",
      "Epoch 100 | Train Loss: 0.025 | Train Acc: 100.00%| Val Loss: 0.73 | Val Acc: 77.00%\n"
     ]
    }
   ],
   "source": [
    "# Train GCN model on Cora dataset\n",
    "gcn_cora.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = gcn_cora(data_cora.x, data_cora.edge_index)\n",
    "    loss = criterion(y_pred[data_cora.train_mask], data_cora.y[data_cora.train_mask]) # loss = criterion(y_pred, y_true)\n",
    "    acc = accuracy(y_pred[data_cora.train_mask].argmax(dim=1), data_cora.y[data_cora.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_cora.val_mask], data_cora.y[data_cora.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_cora.val_mask].argmax(dim=1), data_cora.y[data_cora.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff627446-866a-49c7-9ccb-0746893f9410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GCN test accuracy for Cora dataset: 79.70%\n"
     ]
    }
   ],
   "source": [
    "# Test GCN model on Cora dataset\n",
    "gcn_cora.eval()\n",
    "y_pred = gcn_cora(data_cora.x, data_cora.edge_index)\n",
    "test_acc = accuracy(y_pred[data_cora.test_mask].argmax(dim=1), data_cora.y[data_cora.test_mask])\n",
    "print(f'\\nGCN test accuracy for Cora dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48327c10-d43d-4d6b-92e3-28401e5ff137",
   "metadata": {},
   "source": [
    "### GCN for Facebook Page-Page dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ea2d1df-9969-4feb-93f9-5eae813afc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(128, 16)\n",
       "  (gcn2): GCNConv(16, 4)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_fb = GCN(dataset_facebook.num_features, 16, dataset_facebook.num_classes)\n",
    "gcn_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8dafff7-dfb1-4a1a-9111-ab9dc086a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss() # loss\n",
    "optimizer = torch.optim.Adam(gcn_fb.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "301272e3-b5a1-4ae0-ad35-ba66fcf813e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.343 | Train Acc: 30.43%| Val Loss: 1.35 | Val Acc: 30.77%\n",
      "Epoch  20 | Train Loss: 0.636 | Train Acc: 78.84%| Val Loss: 0.63 | Val Acc: 78.94%\n",
      "Epoch  40 | Train Loss: 0.424 | Train Acc: 85.89%| Val Loss: 0.42 | Val Acc: 86.39%\n",
      "Epoch  60 | Train Loss: 0.343 | Train Acc: 89.16%| Val Loss: 0.34 | Val Acc: 89.34%\n",
      "Epoch  80 | Train Loss: 0.306 | Train Acc: 90.25%| Val Loss: 0.30 | Val Acc: 90.20%\n",
      "Epoch 100 | Train Loss: 0.285 | Train Acc: 90.97%| Val Loss: 0.28 | Val Acc: 91.10%\n"
     ]
    }
   ],
   "source": [
    "# Train GCN model on Facebook Page-Page dataset\n",
    "gcn_fb.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = gcn_fb(data_facebook.x, data_facebook.edge_index)\n",
    "    loss = criterion(y_pred[data_facebook.train_mask], data_facebook.y[data_facebook.train_mask]) # loss = criterion(y_pred, y_true)\n",
    "    acc = accuracy(y_pred[data_facebook.train_mask].argmax(dim=1), data_facebook.y[data_facebook.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_facebook.val_mask], data_facebook.y[data_facebook.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_facebook.val_mask].argmax(dim=1), data_facebook.y[data_facebook.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a2cb46a-f357-4268-9061-db03e2e1b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GCN test accuracy for Facebook Page-Page dataset: 89.83%\n"
     ]
    }
   ],
   "source": [
    "# Test GCN model on Facebook Page-Page dataset\n",
    "gcn_fb.eval()\n",
    "y_pred = gcn_fb(data_facebook.x, data_facebook.edge_index)\n",
    "test_acc = accuracy(y_pred[data_facebook.test_mask].argmax(dim=1), data_facebook.y[data_facebook.test_mask])\n",
    "print(f'\\nGCN test accuracy for Facebook Page-Page dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc856987-33bb-42e7-b434-a73fdabb65e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

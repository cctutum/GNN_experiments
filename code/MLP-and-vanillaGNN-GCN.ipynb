{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7efc70e-36b6-4f2d-b984-fb41bf3d7b29",
   "metadata": {},
   "source": [
    "## Import Cora and Facebook/Page-Page daasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4012426d-bef6-4bc1-8195-6b025c482bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Data(x=[22470, 128], edge_index=[2, 342004], y=[22470], train_mask=[18000], val_mask=[1999], test_mask=[2469])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import FacebookPagePage\n",
    "\n",
    "dataset_cora = Planetoid(root=\"../data\", name=\"Cora\")\n",
    "dataset_facebook = FacebookPagePage(root=\"../data/Facebook-Page-Page\")\n",
    "\n",
    "data_cora = dataset_cora[0]\n",
    "data_facebook = dataset_facebook[0]\n",
    "\n",
    "# Unlike Cora, Facebook Page-Page doesn’t have training, evaluation, and test masks by\n",
    "# default. We can arbitrarily create masks with the range() function:\n",
    "data_facebook.train_mask = range(18000)\n",
    "data_facebook.val_mask = range(18001, 20000)\n",
    "data_facebook.test_mask = range(20001, 22470)\n",
    "\n",
    "print(data_cora)\n",
    "print(data_facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ba3dc-ddb0-4629-a81c-86e5736fea50",
   "metadata": {},
   "source": [
    "Cora is a popular dataset for node classification in the scientific literature. It represents a network of 2,708 publications (**nodes**), where each connection is a reference (**edge**). Each publication is described as a binary vector of 1,433 unique words (**node features**), where 0 and 1 indicate the absence or presence of the corresponding word, respectively. Each node has a class label from 7 **classes**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917c116-99d7-4d4d-98bd-fcd6a42ce6e0",
   "metadata": {},
   "source": [
    "## Classifying nodes with vanilla neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9165e5-ab80-4de6-aa67-4e2e19da6c10",
   "metadata": {},
   "source": [
    "We will consider node features (i.e., 1,433) as a regular tabular dataset. We will train a simple neural\n",
    "network (MLP) on this dataset to classify our nodes. Note that this architecture does not take into account\n",
    "the topology of the network. We will try to fix this issue with a vanilla GNN and GCN, then compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc6b31e-c00a-445c-b630-2e4f5110df9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "2703  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
       "2704  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2705  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2706  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      1427  1428  1429  1430  1431  1432  label  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "...    ...   ...   ...   ...   ...   ...    ...  \n",
       "2703   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2704   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2705   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2706   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2707   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[2708 rows x 1434 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is just to show the feature matrix and class vector (we need torch.Tensor type input --> data_cora.x)\n",
    "df_x = pd.DataFrame(data_cora.x.numpy()) # 1,433 columns\n",
    "df_x['label'] = pd.DataFrame(data_cora.y) # adding a label-column\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec16c842-d6e6-49aa-81d5-7407645d7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e932d29-f64f-4ed5-8f02-7d55c9fad590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(dim_input, dim_hidden)\n",
    "        self.linear2 = Linear(dim_hidden, dim_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model_cora = MLP(dataset_cora.num_features, 16, dataset_cora.num_classes)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "model_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6778d965-a6b3-40c3-9d78-9ffdf19f0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1433])\n",
      "tensor([[-1.9166, -2.1035, -1.9224, -2.0546, -1.8943, -1.7017, -2.0902]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([1, 7])\n",
      "tensor([5])\n"
     ]
    }
   ],
   "source": [
    "input = data_cora.x[:1,:]\n",
    "print(input.shape)\n",
    "print(model_cora(input))\n",
    "print(model_cora(input).shape)\n",
    "print(model_cora(input).argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f64cb8-d859-4fe8-8b28-e78896700bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple accuracy metric (not the best metric for multiclass classification) \n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss() # loss\n",
    "optimizer = torch.optim.Adam(model_cora.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06675633-5d2b-4d15-9641-fecc6d0e122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.960 | Train Acc: 14.29%| Val Loss: 1.96 | Val Acc: 11.40%\n",
      "Epoch  20 | Train Loss: 0.556 | Train Acc: 100.00%| Val Loss: 1.55 | Val Acc: 48.60%\n",
      "Epoch  40 | Train Loss: 0.094 | Train Acc: 100.00%| Val Loss: 1.40 | Val Acc: 51.60%\n",
      "Epoch  60 | Train Loss: 0.037 | Train Acc: 100.00%| Val Loss: 1.37 | Val Acc: 54.20%\n",
      "Epoch  80 | Train Loss: 0.022 | Train Acc: 100.00%| Val Loss: 1.37 | Val Acc: 54.00%\n",
      "Epoch 100 | Train Loss: 0.017 | Train Acc: 100.00%| Val Loss: 1.37 | Val Acc: 54.00%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model on Cora dataset\n",
    "model_cora.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_cora(data_cora.x)\n",
    "    loss = criterion(y_pred[data_cora.train_mask], data_cora.y[data_cora.train_mask]) # loss = criterion(y_pred, y_true)\n",
    "    acc = accuracy(y_pred[data_cora.train_mask].argmax(dim=1), data_cora.y[data_cora.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_cora.val_mask], data_cora.y[data_cora.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_cora.val_mask].argmax(dim=1), data_cora.y[data_cora.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f60f45ee-089c-4554-b9cd-84af0ed56376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP test accuracy for Cora dataset: 54.10%\n"
     ]
    }
   ],
   "source": [
    "# Test MLP model on Cora dataset    \n",
    "model_cora.eval()\n",
    "y_pred = model_cora(data_cora.x)\n",
    "acc = accuracy(y_pred[data_cora.test_mask].argmax(dim=1), data_cora.y[data_cora.test_mask])\n",
    "print(f'\\nMLP test accuracy for Cora dataset: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa3415-02c1-4072-9290-eb5823a19d22",
   "metadata": {},
   "source": [
    "## Repeat the process for the Facebook Page-Page dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de019e45-c618-4057-a3e6-cf3fc060eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fb = MLP(dataset_facebook.num_features, 16, dataset_facebook.num_classes)\n",
    "model_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12bd314c-6285-4e85-869f-f03391bdd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.416 | Train Acc: 25.76%| Val Loss: 1.41 | Val Acc: 25.16%\n",
      "Epoch  20 | Train Loss: 0.832 | Train Acc: 68.37%| Val Loss: 0.84 | Val Acc: 66.68%\n",
      "Epoch  40 | Train Loss: 0.641 | Train Acc: 74.78%| Val Loss: 0.66 | Val Acc: 73.74%\n",
      "Epoch  60 | Train Loss: 0.589 | Train Acc: 76.50%| Val Loss: 0.62 | Val Acc: 74.74%\n",
      "Epoch  80 | Train Loss: 0.566 | Train Acc: 77.34%| Val Loss: 0.61 | Val Acc: 76.04%\n",
      "Epoch 100 | Train Loss: 0.552 | Train Acc: 77.88%| Val Loss: 0.60 | Val Acc: 75.89%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model on Facebook Page-Page dataset\n",
    "optimizer = torch.optim.Adam(model_fb.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "model_fb.train()\n",
    "for epoch in range(num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_fb(data_facebook.x)\n",
    "    train_loss = criterion(y_pred[data_facebook.train_mask], data_facebook.y[data_facebook.train_mask])\n",
    "    train_acc = accuracy(y_pred[data_facebook.train_mask].argmax(dim=1), data_facebook.y[data_facebook.train_mask])\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch % 20) == 0:\n",
    "        val_loss = criterion(y_pred[data_facebook.val_mask], data_facebook.y[data_facebook.val_mask])\n",
    "        val_acc = accuracy(y_pred[data_facebook.val_mask].argmax(dim=1), data_facebook.y[data_facebook.val_mask])\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:>5.2f}%'\n",
    "              f'| Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f45f96d6-7da9-4d67-89a5-6a4b928a0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP test accuracy for Facebook Page-Page dataset: 74.44%\n"
     ]
    }
   ],
   "source": [
    "# Test MLP model on Facebook Page-Page dataset   \n",
    "model_fb.eval()\n",
    "y_pred = model_fb(data_facebook.x)\n",
    "test_acc = accuracy(y_pred[data_facebook.test_mask].argmax(dim=1), data_facebook.y[data_facebook.test_mask])\n",
    "print(f'\\nMLP test accuracy for Facebook Page-Page dataset: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7895901-2a4a-49ee-9e8e-5cf0abd46ac1",
   "metadata": {},
   "source": [
    "## Classifying nodes with vanilla graph neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbf100-3e3b-4e36-bd88-51b245f7d7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
